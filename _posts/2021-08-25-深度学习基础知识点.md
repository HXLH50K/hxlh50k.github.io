---
layout: post
title: 深度学习基础知识点
subtitle: 未完成，随缘更新
date: 2021-08-25
author: hxlh50k
header-img: null
catalog: true
tags:
  - 机器学习
  - 深度学习
---

# 优化算法

## GD

1. 确定优化模型的假设函数及损失函数。
2. 初始化参数，随机选取取值范围内的任意数；
3. 迭代操作：
   1. 计算当前梯度
   2. 修改新的变量
   3. 计算朝最陡的下坡方向走一步
   4. 判断是否需要终止，如否，梯度更新
   5. 得到全局最优解或者接近全局最优解。

## BGD 批量梯度下降法

1. 采用所有数据来梯度下降。
2. 批量梯度下降法在样本量很大的时候，训练速度慢。

## SGD 随机梯度下降法

1. 随机梯度下降用一个样本来梯度下降。
2. 训练速度很快。
3. 随机梯度下降法仅仅用一个样本决定梯度方向，导致解有可能不是全局最优。
4. 收敛速度来说，随机梯度下降法一次迭代一个样本，导致迭代方向变化很大，不能很快的收敛到局部最优解。

## MBGD 小批量梯度下降

前两者折中

## 动量优化算法

- GD 缺点：当接近最优值时梯度会比较小，由于学习率固定，收敛速度会变慢，有时甚至陷入局部最优。
- 动量基本思想：考虑历史梯度，引导参数朝着最优值更快收敛。直观上来说，要是当前时刻的梯度与历史梯度方向趋近，这种趋势会在当前时刻加强，否则当前时刻的梯度方向减弱。如果两个坐标轴梯度差距大，会在大梯度的轴上震荡

## 牛顿动量（Nesterov）算法

不在当前时刻修正梯度，而是预测下一次的位置，进行梯度修正。可以减弱震荡

# 自适应学习率优化算法

## Adagrad

1. 独立设置参数空间每个轴方向上的学习率
2. 参数空间每个方向的学习率反比于 x 的平方根。x=该方向上梯度分量的所有历史平方值之和。 $$ \vec{r}\leftarrow\vec{r}+\hat{\vec{g}}\odot\hat{\vec{g}} $$  
   $$ \vec{\theta}\leftarrow\vec{\theta}-\frac{\epsilon}{\sqrt{\vec{r}}}\odot\hat{\vec{g}} $$

## RMSProp

1. 将 Adagrad 梯度累计策略修改为指数加权的移动平均 $$ \vec{r}\leftarrow\rho\vec{r}+(1-\rho)\hat{\vec{g}}\odot\hat{\vec{g}} $$  
   $$ \vec{\theta}\leftarrow\vec{\theta}-\frac{\epsilon}{\sqrt{\vec{r}}}\odot\hat{\vec{g}} $$

## AdaDelta

1. 将 Adagrad 梯度累计策略修改为只考虑过去窗口 window 内的梯度。
2. RMSProp 可以认为是一种软化的 AdaDelta，衰减速率 $window=\frac{1}{1-ρ}$。

## Adam

1. RMSProp 算法中，通过累计平方梯度（采用指数移动平均）来修正学习率。
2. 而 Adam 算法中，不仅采用同样的方式来修正学习率，还通过累计梯度（采用指数移动平均）来修正梯度。

# batch-size 如何设置

过小：花费时间多，同时梯度震荡严重，不利于收敛过大：不同 batch 的梯度方向没有任何变化，容易陷入局部极小值

# 正则化：

- L1、L2 都是对损失函数的优化，L 范式都是为了防止模型过拟合，所谓范式就是加入参数的约束。
- L1 的作用是为了矩阵稀疏化。假设的是模型的参数取值满足拉普拉斯分布。
- L2 的作用是为了使模型更平滑，得到更好的泛化能力。假设的是参数是满足高斯分布，L2 对大数和异常值更敏感。

# 常见损失函数

<!-- prettier-ignore-start -->
## BCE
$$ L_{BCE}=-\frac{1}{N}\sum^N_{i=1}{y_i\log{p_i}+(1-y_i)\log{(1-p_i)}} $$
$y_i$ 的取值为 $\{0, 1\}$ ，对于每个sample，公式中只有一项生效

## CE
$$ L_{CE}=-\frac{1}{N}\sum^N_{i=1}{\sum^C_{c=1}{y^{(c)}_i\log{p^{(c)}_i}}} $$

## MAE/L1
$$ L_1 = \frac{1}{N}\sum^N_{i=1}{|y_i-p_i|} $$

## Smooth L1
$$ L_{s1} = \begin{cases} 
0.5x^2 &, & |x|<1 \\
|x|-0.5 &, & |x|\geq1 &
\end{cases}$$

## MSE/L2
$$ L_1 = \frac{1}{N}\sum^N_{i=1}{(y_i-p_i)^2} $$

## FOCAL
$$ L_{FOCAL} = \frac{1}{N}\sum^N_{i=1}{\alpha(1-p_i)^\gamma y_i\log{p_i}+(1-\alpha)p_i^\gamma (1-y_i)\log(1-p_i)} , \alpha=0.25,\gamma=2$$

## DICE
$$ L_{Dice} = 1- 2*\frac{|y\cap p|}{|y|+|p|} $$

## IOU
$$ L_{IOU} = 1-\frac{|y \cap p|}{|y \cup p|} $$

# 激活函数

## sigmoid
$$ f(x) = \frac{1}{1+e^{-x}} $$  
$$ f'(x) = f(x)(1-f(x)) $$
问题：梯度消失，均值不为0  

## hard sigmoid
$$ f(x) = \begin{cases}
0 &,&{x<-2.5}   \\
0.2x-2.5 &,&{-2.5\leq x \leq 2.5}  \\
1 &,&{x>2.5}
\end{cases}$$

## softmax
$$ f(x) = \frac{1}{N}\sum^N_{i=1}{\frac{e^{x_i}}{\sum^{C}_{c=1}{e^{x_i^{(c)}}}}} $$

## tanh
$$ f(x) = \frac{e^x-e^{-x}}{e^x+e^{-x}} $$
解决：均值为0
问题：梯度消失

## ReLU
$$ f(x)=\max⁡(x,0) $$
解决：梯度消失
问题：死区，无穷大

## ReLU6
$$ f(x)=\min⁡(\max⁡(x,0),6)$$
解决：无穷大
问题：死区

## Leaky ReLU
$$ f(x) = \max(x,\alpha x),usually0<\alpha \ll 1 $$
解决：死区
问题：α不好设置

## PReLU
α可学习的Leaky ReLU，所有层相同

## RReLU
α可学习的Leaky ReLU，随机均值/高斯初始化，所有层不同

## ELU
$$ f(x) = \begin{cases}
x &,& x\geq 0 \\
\lambda (e^{-x}-1) &,& x<0
\end{cases} $$
缺点：计算量大

## GeLU (for bert)
$$ xP(X\leq x)=xΦ(x) $$
Φ(x)  is Standard normal distribution.

## Maxout：
一种激活函数层

## Swish
$$ f(x)=x\sigma(\beta x)$$
特点：
* 无上界，不会梯度饱和
* 有下界，可以产生更强的正则化效果
* 非单调
* 处处可导
## H-Swish
$$ f(x) = x\frac{ReLU6(x+3)}{6} $$

# 评价指标

## 分类

### 准确率

$$ Accuracy = \frac{TP+TN}{TP+FN+FP+TN}$$

### 精确率
$$ Precision = \frac{TP}{TP+FP}$$

### 召回率
$$ Recall = \frac{TP}{TP+FN} $$

### F-score
$$ F_β = \frac{(1+\beta^2 )TP}{(1+\beta^2 )TP+\beta^2 FN+FP}$$
当beta大于1，更多关注recall；当beta小于1，更多关注precision。

### AUC/GAUC https://zhuanlan.zhihu.com/p/84350940

#### ROC
给定所有样本的正负和预测的概率值，给定阈值集合{0.1,0.2…0.9}，遍历所有阈值，并查看给定每个阈值的情况下的分类情况如何。横坐标TPR，纵坐标FPR

#### AUC
$$ AUC = \frac{area under ROC}{x*y} = \frac{\sum^M_{i=1}{N_i}}{M*N} $$
有M个正样本，N个负样本

#### GAUC
用于广告推荐领域，计算每个用户的auc，然后加权平均，最后得到group auc，这样就能减少不同用户间的排序结果不太好比较这一影响。

<!-- prettier-ignore-end -->

# Normalization 层

## Normlization 层的作用

加快模型收敛速度，缓解深层网络中“梯度弥散”的问题；

## BN、IN、GN、LN 区别

$ feature map: x\in R^{N×C×H×W} $

- BN：保留 C 求均值，受到 BS 的影响大
- LN：保留 N 求均值，单样本可进行
- IN：保留 N、C 求均值，单样本可进行，起初用于风格迁移
- GN：LN、IN 的折中，将 C 分为 G 组

## BN 计算

<!-- prettier-ignore-start -->
$$ μ_j=\frac{1}{m}\sum_{i=1}^m{Z_j^{(i)}}$$
$$ σ_j^2=\frac{1}{m}\sum_{i=1}^m{(Z_j^{(i)}-\mu_j)^2} $$
$$ \hat{Z_j}=\frac{Z_j-μ_j}{\sqrt{σ_j^2+\epsilon}} $$
$$ \tilde{Z_j}=γ_j*\hat{Z_j}+β_j $$ 
inferenct阶段的 $\mu\ \sigma$ 使用 train 阶段的无偏估计
<!-- prettier-ignore-end -->

- 深层神经网络在做非线性变换前的激活输入值($x=WU+B$)随着网络深度加深或者在训练过程中，其分布逐渐发生偏移或者变动，一般是整体分布逐渐往非线性函数的取值区间的上下限两端靠近（对于 Sigmoid 函数来说，意味着激活输入值 $WU+B$ 是大的负值或正值），导致后向传播时低层神经网络的梯度消失。BN 就是通过一定的规范化手段，把每层神经网络任意神经元这个输入值的分布强行拉回到均值为 0 方差为 1 的标准正态分布，使得激活输入值落在非线性函数对输入比较敏感的区域。
- 归一化后会降低表征能力，BN 为了保证非线性的获得，对变换后的满足均值为 0 方差为 1 的 x 又进行了 scale 加上 shift 操作($y=scale×x+shift$)，每个神经元增加了两个参数 scale 和 shift 参数，这两个参数是通过训练学习到的，意思是通过 scale 和 shift 把这个值从标准正态分布左移或者由移一点并长胖一点或者变瘦一点，每个实例挪动的程度不一样，这样等价于非线性函数的值从正中心周围的线性区往非线性区动了动。核心思想应该是想找到一个线性和非线性的较好平衡点，既能享受非线性的较强表达能力的好处，又避免太靠非线性区两头使得网络收敛速度太慢。

### 优点：

- BN 将 Hidden Layer 的输入分布从饱和区拉到了非饱和区，减小了梯度弥散，提升了训练速度，收敛过程大大加快，还能增加分类效果。
- BatchNorm 本身上也是一种正则的方式（主要缓解了梯度消失），可以代替其他正则方式如 dropout 等。
- 调参过程也简单多了，对于初始化要求没那么高，而且可以使用大的学习率等。

#### 缺点：

- batch normalization 依赖于 batch 的大小，当 batch 值很小时，计算的均值和方差不稳定。
